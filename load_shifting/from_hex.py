# Get your EIA API key for access to the EIA's wealth of data!
# To do this:
#  1. Go to https://www.eia.gov/opendata/ and click "Register"
#  2. Fill out the form and click "Register"
#  3. Follow the verification link in your e-mail (may need to check spam)
#  4. Enter it in quotes below - it will be some long string of characters like 


EIA_API_KEY = os.getenv("EIA_API_KEY")

assert EIA_API_KEY != "", "You must set an EIA API key before continuing."

# From https://www.eia.gov/tools/faqs/faq.php?id=74&t=11
# estimates of CO2e per kwh for fossil fuels:
EMISSIONS_BY_FUEL = {
    "COL": 2.30,
    "NG": 0.97,
    "OIL": 2.38,
    "NUC": 0,
    "SUN": 0,
    "WAT": 0,
    "WND": 0,
    "OTH": 0.86, # from EIA's "average across all power sources", shrug emoji
    "Hydro": 0,
    "Solar": 0,
    "Petroleum": 2.38,
    "Nuclear": 0,
    "Natural gas": 0.97,
    "Wind": 0,
    "Coal": 2.30,
    "Other": 0.86,
}



# Exploration of EIA API:

# looks like some of these have a resource type code of "MWH" for batteries???
api_url = f"https://api.eia.gov/v2/electricity/rto/region-data?api_key={EIA_API_KEY}"
requests.get(api_url).json()


# helper functions to fetch data from the EIA API

# There are three types of data we're fetching:
#  1. Generation by fuel type (Megawatt-hours): how much electricity is being generated by each fuel type
#  2. Demand (Megawatt-hours): how much electricity is being consumed
#  3. Interchange: how much electricity is being imported/exported from other balancing authorities

default_end_date = datetime.date.today().isoformat()
default_start_date = (datetime.date.today() - datetime.timedelta(days=365)).isoformat()


def get_eia_timeseries(
    url_segment,
    facets,
    value_column_name="value",
    start_date=default_start_date,
    end_date=default_end_date,
    start_page=0,
    frequency="daily",
    include_timezone=True
):
    """
    A generalized helper function to fetch data from the EIA API
    """

    max_row_count = 5000  # This is the maximum allowed per API call from the EIA
    api_url = f"https://api.eia.gov/v2/electricity/rto/{url_segment}/data/?api_key={EIA_API_KEY}"
    offset = start_page * max_row_count

    if include_timezone and not "timezone" in facets:
        facets = dict(**{"timezone": ["Pacific"]}, **facets)

    response_content = requests.get(
        api_url,
        headers={
            "X-Params": json.dumps(
                {
                    "frequency": frequency,
                    "data": ["value"],
                    "facets": facets,
                    "start": start_date,
                    "end": end_date,
                    "sort": [{"column": "period", "direction": "desc"}],
                    "offset": offset,
                    "length": max_row_count,
                }
            )
        },
    ).json()
    print(response_content)

    # Sometimes EIA API responses are nested under a "response" key. Sometimes not ðŸ¤·
    if "response" in response_content:
        response_content = response_content["response"]

    print(f"{len(response_content['data'])} rows fetched")

    # Convert the data to a Pandas DataFrame and clean it up for plotting & analysis.
    dataframe = pd.DataFrame(response_content["data"])
    # Add a more useful timestamp column
    dataframe["timestamp"] = dataframe["period"].apply(
        pd.to_datetime, format="%Y/%m/%dT%H"
    )
    # Clean up the "value" column-
    # EIA always sends the value we asked for in a column called "value"
    # Oddly, this is sometimes sent as a string though it should always be a number.
    # We convert its dtype and set the name to a more useful one
    eia_value_column_name = "value"
    processed_df = dataframe.astype({eia_value_column_name: float}).rename(
        columns={eia_value_column_name: value_column_name}
    )

    # Pagination logic
    rows_fetched = len(processed_df) + offset
    rows_total = int(response_content["total"])
    more_rows_needed = rows_fetched != rows_total
    if more_rows_needed:
        # Recursive call to get remaining rows
        additional_rows = get_eia_timeseries(
            url_segment=url_segment,
            facets=facets,
            value_column_name=value_column_name,
            start_date=start_date,
            end_date=end_date,
            start_page=start_page + 1,
            frequency=frequency,
            include_timezone=include_timezone
        )
        return pd.concat([processed_df, additional_rows])
    else:
        return processed_df


def get_daily_eia_grid_mix_timeseries(balancing_authorities, **kwargs):
    """
    Fetch electricity generation data by fuel type
    """
    return get_eia_timeseries(
        url_segment="daily-fuel-type-data",
        facets={"respondent": balancing_authorities},
        value_column_name="Generation (MWh)",
        **kwargs,
    )

def get_hourly_eia_grid_mix(balancing_authorities, **kwargs):
    """
    Fetch elecgtricity generation data by fuel type, but hourly
    """
    return get_eia_timeseries(
        url_segment="fuel-type-data",
        facets={"respondent": [balancing_authorities]},
        value_column_name="Generation (MWh)",
        frequency="local-hourly",
        include_timezone=False,
        **kwargs,
    )


def get_daily_eia_net_demand_and_generation_timeseries(balancing_authorities, **kwargs):
    """
    Fetch electricity demand data
    """
    return get_eia_timeseries(
        url_segment="daily-region-data",
        facets={
            "respondent": balancing_authorities,
            "type": ["D", "NG", "TI"],  # Filter out the "Demand forecast" (DF) type
        },
        value_column_name="Demand (MWh)",
        **kwargs,
    )

def get_hourly_eia_net_demand_and_generation(balancing_authorities, **kwargs):
    """
        Fetch electricity demand data but hourly
    """
    return get_eia_timeseries(
        url_segment="region-data",
        facets={"respondent": [balancing_authorities],
        "type": ["D", "NG", "TI"],
        },
        value_column_name="Demand (MWh)",
        frequency="local-hourly",
        include_timezone=False,
        **kwargs
    )


def get_daily_eia_interchange_timeseries(balancing_authorities, **kwargs):
    """
    Fetch electricity interchange data (imports & exports from other utilities)
    """
    return get_eia_timeseries(
        url_segment="daily-interchange-data",
        facets={"toba": balancing_authorities},
        value_column_name=f"Interchange to local BA (MWh)",
        **kwargs,
    )

def get_hourly_eia_interchange(balancing_authorities, **kwargs):
    """
    Fetch electricity interchange data (imports & exports) but hourly
    """
    return get_eia_timeseries(
        url_segment="interchange-data",
        facets={"toba": [LOCAL_BALANCING_AUTHORITY],
        },
        value_column_name=f"Interchange to local BA (MWh)",
        frequency="local-hourly",
        include_timezone=False,
        **kwargs
    )



# In this cell, you'll be making one change!

# This cell defines the local balancing authority for which we're fetching grid mix data

# Currently, we've set this to "PSEI", i.e.Puget Sound Energy, Inc., the balancing authority for the region around Seattle, WA

# Change this to a different valid balancing authority:
#  - Visit the EIA API docs here: https://www.eia.gov/electricity/gridmonitor/dashboard/electric_overview/US48/US48
#  - Explore the map to find the 3-4 letter acronym representing a different balancing authority
#  - Update the line below with the value you found, then re-run this cell (Shift+Enter, or use the "play" icon in the upper right of this cell)
LOCAL_BALANCING_AUTHORITY = "CISO"


# Explore supply/demand data to see if there's any battery discharge data in there:
all_hourly_region_data = get_eia_timeseries(
        url_segment="region-data",
        facets={"respondent": [LOCAL_BALANCING_AUTHORITY],
        #"type": ["D", "NG", "TI"], # this filters out only "day-ahead demand forecast"
        },
        value_column_name="Demand (MWh)",
        frequency="local-hourly",
        include_timezone=False
    )
all_hourly_region_data["type-name"].unique()


# In this cell, we put it all together and actually make a request against the EIA API to fetch electricity generation data
# You do not need to make changes to this cell

local_generation_grid_mix = get_hourly_eia_grid_mix(
    [LOCAL_BALANCING_AUTHORITY],
    # Optional: uncomment the lines below to try looking at a different time range to get data from other seasons.
    # start_date="2022-01-01",
    # end_date="2023-01-01",
)

# Listing this variable alone on the last line causes hex to display it, so we get a preview of the data as a table
local_generation_grid_mix["type-name"].unique()




local_generation_grid_mix["emissions_per_kwh"] = local_generation_grid_mix["fueltype"].apply(
    lambda x: EMISSIONS_BY_FUEL[x])
local_generation_grid_mix["emissions"] = local_generation_grid_mix["emissions_per_kwh"] * local_generation_grid_mix["Generation (MWh)"] * 1000

intensity_by_hour = local_generation_grid_mix[["Generation (MWh)", "emissions", "timestamp"]].groupby(
    ["timestamp"]).aggregate("sum").reset_index()

intensity_by_hour["local_pounds_co2_per_kwh"] = intensity_by_hour["emissions"] / (intensity_by_hour["Generation (MWh)"]*1000)

intensity_by_hour["hour"] = intensity_by_hour.timestamp.apply(lambda x: x.hour)
intensity_by_hour["month"] = intensity_by_hour.timestamp.apply(lambda x: x.month)
# Note we get different results here depending on whether we treat this avg as "all hours weighted equally" (current behavior)
# vs "all kwh weighted equally" (big kwh days matter more)
avg_intensity_by_hour = intensity_by_hour[["hour", "local_pounds_co2_per_kwh"]].groupby(["hour"]).aggregate("mean").reset_index()
avg_intensity_by_month = intensity_by_hour[["month", "local_pounds_co2_per_kwh"]].groupby(["month"]).aggregate("mean").reset_index()



# First, more terminology (https://www.eia.gov/electricity/gridmonitor/about)

# Demand (D): energy consumed locally
# Net generation (NG): energy generated locally
# Total interchange (TI): net energy exported (positive means net outflow, negative means net inflow)

# The balancing authority is responsible for balancing this equation:
# Total interchange = Net generation - Demand
# i.e. if local generation is larger than local demand, the BA is exporting electricity (positive total interchange)
#      if local demand is larger than local generation, the BA is importing electricity (negative total interchange)


# There are two paths to consider:

# 1. Local BA is a net exporter of energy
# In this case, all electricity consumed locally comes from electricity generated locally, so the grid mix simply matches the local generation
# This turns out to be a trivial sub-case of path #2

# 2. Local BA is a net importer of energy
# When the local BA is net importing energy, that energy might come from multiple other BAs, each of which has their own grid mix
# Therefore, the grid mix of consumed electricity is a combination of local generation grid mix and imported generation grid mix

# To get a true representation of the grid mix of local energy, we need to combine these pieces of data:
#  - Demand, Net generation, and Total interchange for our LOCAL_BALANCING_AUTHORITY
#  - Interchange (quantitiy of imported energy) with each connected balancing authority
#  - Grid mix of imported energy from each connected balancing authority



# In the code below, we fetch the daily Demand (D), Net generation (NG), and Total interchange (TI) numbers for the LOCAL_BALANCING_AUTHORITY
# You should see three rows for each date, one row each for TI, D, and NG.
# You can spot check a given day to confirm that TI = NG - D
#demand_df = get_eia_net_demand_and_generation_timeseries([LOCAL_BALANCING_AUTHORITY])
# Changed to hourly instead of daily:
demand_df = get_hourly_eia_net_demand_and_generation([LOCAL_BALANCING_AUTHORITY])
demand_df


#response_content = requests.get(
#        f"https://api.eia.gov/v2/electricity/rto/interchange-data/data/?api_key={EIA_API_KEY}",
#        headers={
#            "X-Params": json.dumps(
#                {
#                    "frequency": "local-hourly",
#                    "data": ["value"],
#                    "facets": {"toba": [LOCAL_BALANCING_AUTHORITY],
#                    },
#                    "start": one_month_ago,
#                    "end": today,
#                    "sort": [{"column": "period", "direction": "desc"}],
#                    "offset": 0,
#                    "length": 50000,
#                }
#            )
#        },
#).json()
#response_content



# Supply and demand by hour of day:
demand_df["hour"] = demand_df.timestamp.apply(lambda x: x.hour)
demand_by_hour = demand_df[["hour", "Demand (MWh)", "type-name"]].groupby(["hour", "type-name"]).sum().reset_index()



# Was daily:
# interchange_df = get_eia_interchange_timeseries([LOCAL_BALANCING_AUTHORITY])
# Now hourly:
interchange_df = get_hourly_eia_interchange([LOCAL_BALANCING_AUTHORITY])
interchange_df



# How much energy is both generated and consumed locally
def get_energy_generated_and_consumed_locally(df):
    demand_stats = df.groupby("type-name")["Demand (MWh)"].sum()
    # If local demand is smaller than net (local) generation, that means: amount generated and used locally == Demand (net export)
    # If local generation is smaller than local demand, that means: amount generated and used locally == Net generation (net import)
    # Therefore, the amount generated and used locally is the minimum of these two
    try:
        return min(demand_stats["Demand"], demand_stats["Net generation"])
    except KeyError:
        # Sometimes for a particular timestamp we're missing demand or net generation. Be conservative and set it to zero
        print(f'Warning - either Demand or Net generation is missing from this timestamp. Values found for "type-name": {list(demand_stats.index)}')
        return 0

# TODO: the above seems to be printing out an awful lot of warnings. Is this a problem?

energy_generated_and_used_locally = demand_df.groupby("timestamp").apply(
    get_energy_generated_and_consumed_locally
)

consumed_locally_column_name = "Power consumed locally (MWh)"

# How much energy is imported and then used locally, grouped by the source BA (i.e. the BA which generated the energy)
energy_imported_then_consumed_locally_by_source_ba = (
    interchange_df.groupby(["timestamp", "fromba"])[
        "Interchange to local BA (MWh)"
    ].sum()
    # We're only interested in data points where energy is coming *in* to the local BA, i.e. where net export is negative
    # Therefore, ignore positive net exports
    .apply(lambda interchange: max(interchange, 0))
)

# Combine these two together to get all energy used locally, grouped by the source BA (both local and connected)
energy_consumed_locally_by_source_ba = pd.concat(
    [
        energy_imported_then_consumed_locally_by_source_ba.rename(
            consumed_locally_column_name
        ).reset_index("fromba"),
        pd.DataFrame(
            {
                "fromba": LOCAL_BALANCING_AUTHORITY,
                consumed_locally_column_name: energy_generated_and_used_locally,
            }
        ),
    ]
).reset_index()




# Now that we know how much (if any) energy is imported by our local BA, and from which source BAs,
# let's get a full breakdown of the grid mix (fuel types) for that imported energy.

# First, get a list of all source BAs: our local BA plus the ones we're importing from
all_source_bas = energy_consumed_locally_by_source_ba["fromba"].unique().tolist()

# Then, fetch the fuel type breakdowns for each of those BAs
generation_types_by_ba = get_hourly_eia_grid_mix(all_source_bas).rename(
    {"respondent": "fromba", "type-name": "generation_type"}, axis="columns"
)
print(len(generation_types_by_ba))


# Okay, we've fetched all the data we need, now it's time to combine it all together!

# What follows is some heavy-lifting with the Pandas library to massage the data into the shape we want
# Pandas docs: https://pandas.pydata.org/docs/
# Pandas cheat sheet: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf

# The goal is to get a DataFrame of energy used at the local BA (in MWh), broken down by both
#  * the BA that the energy came from, and 
#  * the fuel type of that energy.
# So we'll end up with one row for each combination of source BA and fuel type.

# To get there, we need to combine the amount of imported energy from each source ba with grid mix for that source BA.
# The general formula is:
# Power consumed locally from a (BA, fuel type) combination = 
#    total power consumed locally from this source BA * (fuel type as a % of source BA's generation)
# fuel type as a % of source BA's generation = 
#    (total generation at source BA) / (total generation for this fuel type at this BA)


total_generation_by_source_ba = generation_types_by_ba.groupby(["timestamp", "fromba"])[
    "Generation (MWh)"
].sum()

generation_types_by_ba_with_totals = generation_types_by_ba.join(
    total_generation_by_source_ba,
    how="left",
    on=["timestamp", "fromba"],
    rsuffix=" Total",
)
generation_types_by_ba_with_totals["Generation (% of BA generation)"] = (
    generation_types_by_ba_with_totals["Generation (MWh)"]
    / generation_types_by_ba_with_totals["Generation (MWh) Total"]
)
generation_types_by_ba_with_totals_and_source_ba_breakdown = generation_types_by_ba_with_totals.merge(
    energy_consumed_locally_by_source_ba.rename(
        {"Power consumed locally (MWh)": "Power consumed locally from source BA (MWh)"},
        axis="columns",
    ),
    on=["timestamp", "fromba"],
)
full_df_reindexed = (
    generation_types_by_ba_with_totals_and_source_ba_breakdown.set_index(
        ["timestamp", "fromba", "generation_type"]
    )
)
usage_by_ba_and_generation_type = (
    (
        full_df_reindexed["Power consumed locally from source BA (MWh)"]
        * full_df_reindexed["Generation (% of BA generation)"]
    )
    .rename("Usage (MWh)")
    .reset_index()
)


usage_by_ba_and_generation_type["emissions_per_kwh"] = usage_by_ba_and_generation_type["generation_type"].apply(lambda x: EMISSIONS_BY_FUEL[x])
usage_by_ba_and_generation_type["emissions"] = usage_by_ba_and_generation_type["emissions_per_kwh"] * usage_by_ba_and_generation_type["Usage (MWh)"] * 1000


usage_by_ba_and_generation_type   # Plot this




#requests.get(f"https://api.eia.gov/v2/electricity/rto/fuel-type-data?api_key={EIA_API_KEY}").json()
#requests.get(f"https://api.eia.gov/v2/electricity/rto/fuel-type-data?api_key={EIA_API_KEY}",
#    headers={
#            "X-Params": json.dumps(
#                {
#                    "frequency": "local-hourly",
#                    "data": ["value"],
#                    "facets": dict(**{"timezone": ["Pacific"]}, **facets),
#                    "start": start_date,
#                    "end": end_date,
#                    "sort": [{"column": "period", "direction": "desc"}],
#                    "offset": offset,
#                    "length": max_row_count,
#                }
#            )
#        },
#).json()



# Now that we have usage by fuel type (and resulting carbon-intensity) corrected for imports to our grid,
# we can correct the earlier calculation of emissions-per-unit-energy-by-hour and -by-month.

corrected_intensity_by_hour = usage_by_ba_and_generation_type[["Usage (MWh)", "emissions", "timestamp"]].groupby(
    ["timestamp"]).aggregate("sum").reset_index()

corrected_intensity_by_hour["pounds_co2_per_kwh"] = corrected_intensity_by_hour["emissions"] / (corrected_intensity_by_hour["Usage (MWh)"]*1000)

# Join this with the un-corrected one so we can compare

corrected_intensity_by_hour = corrected_intensity_by_hour.merge(intensity_by_hour, on="timestamp", how="left")
corrected_intensity_by_hour["hour"] = corrected_intensity_by_hour.timestamp.apply(lambda x: x.hour)
corrected_intensity_by_hour["month"] = corrected_intensity_by_hour.timestamp.apply(lambda x: x.month)
# Note we get different results here depending on whether we treat this avg as "all hours weighted equally" (current behavior)
# vs "all kwh weighted equally" (big kwh days matter more)
c_avg_intensity_by_hour = corrected_intensity_by_hour[["hour", "local_pounds_co2_per_kwh", "pounds_co2_per_kwh"]].groupby(["hour"]).aggregate("mean").reset_index()
c_avg_intensity_by_month = corrected_intensity_by_hour[["month", "local_pounds_co2_per_kwh", "pounds_co2_per_kwh"]].groupby(["month"]).aggregate("mean").reset_index()

